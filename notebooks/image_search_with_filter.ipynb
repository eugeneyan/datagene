{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from logger import logger\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import merge, Input\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from imagenet_utils import decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# current_dir = '../data/images/train'\n",
    "# new_dir = '../data/images/all_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create top level category dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '../data/images_sample/train/'\n",
    "# train_top_level_dir = '../data/images_sample/train/'\n",
    "train_top_level_dir = '../data/images_sample/train_top_level/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_level_dict = dict()\n",
    "\n",
    "for image_dir in os.listdir(train_dir):\n",
    "    if not image_dir.startswith('.'):\n",
    "        top_level_category = image_dir.split('->')[0].strip()\n",
    "        try:\n",
    "            top_level_dict[top_level_category] += 1\n",
    "        except:\n",
    "            top_level_dict[top_level_category] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for top_level_category in top_level_dict.keys():\n",
    "    try:\n",
    "        os.makedirs(os.path.join(train_top_level_dir, top_level_category))\n",
    "    except OSError:\n",
    "        logger.info('{} already exists in {}'.format(top_level_category, train_top_level_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy  to top level category directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# images_copied = 0\n",
    "\n",
    "# for image_dir in os.listdir(train_dir):\n",
    "#     if not image_dir.startswith('.'):\n",
    "#         image_paths = os.listdir(os.path.join(train_dir, image_dir))\n",
    "#         image_count = len(image_paths)\n",
    "#         top_level_image_dir = image_dir.split('->')[0].strip()\n",
    "#         print image_dir, '|', top_level_image_dir\n",
    "        \n",
    "#         for image in image_paths:\n",
    "#             if not image.startswith('.'):\n",
    "#                 original_image_path = os.path.join(train_dir, image_dir, image)\n",
    "#                 new_image_path = os.path.join(train_top_level_dir, top_level_image_dir, image)\n",
    "#                 shutil.copy(original_image_path, new_image_path)\n",
    "        \n",
    "#         images_copied += image_count\n",
    "#         logger.info('{} images copied so far'.format(images_copied))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count total number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_count_total = 0\n",
    "\n",
    "for image_dir in os.listdir(train_top_level_dir):\n",
    "    if not image_dir.startswith('.'):\n",
    "        image_names = os.listdir(os.path.join(train_top_level_dir, image_dir))\n",
    "        image_names = [image_name for image_name in image_names if not image_name.startswith('.')]\n",
    "        image_count = len(image_names)\n",
    "        print image_dir, image_count\n",
    "        image_count_total += image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_count_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create index to image.jpeg dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_image_names = list()\n",
    "\n",
    "for image_dir in os.listdir(train_top_level_dir):\n",
    "    if not image_dir.startswith('.'):\n",
    "        image_names = os.listdir(os.path.join(train_top_level_dir, image_dir))\n",
    "        \n",
    "        for image_name in image_names:\n",
    "            if not image_name.startswith('.'):\n",
    "                all_image_names.append(os.path.join(train_top_level_dir, image_dir, image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_image_dict = dict()\n",
    "\n",
    "for i, image_name in enumerate(all_image_names):\n",
    "    idx_to_image_dict[i] = image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "idx_to_image_dict = dict()\n",
    "\n",
    "for image_dir in os.listdir(train_top_level_dir):\n",
    "    if not image_dir.startswith('.'):\n",
    "        image_names = os.listdir(os.path.join(train_top_level_dir, image_dir))\n",
    "        \n",
    "        for image_name in image_names:\n",
    "            if not image_name.startswith('.'):\n",
    "                idx_to_image_dict[index] = os.path.join(train_top_level_dir, image_dir, image_name)\n",
    "                index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_image_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create category to int dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_to_int_dict = dict()\n",
    "idx = 0\n",
    "\n",
    "for image_dir in os.listdir(train_top_level_dir):\n",
    "    if not image_dir.startswith('.'):\n",
    "        image_names = os.listdir(os.path.join(train_top_level_dir, image_dir))\n",
    "        image_names = [image_name for image_name in image_names if not image_name.startswith('.')]\n",
    "        image_count = len(image_names)\n",
    "        \n",
    "        category_to_int_dict[image_dir] = (idx, image_count)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_to_int_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# category_to_int_dict = dict()\n",
    "# idx = 0\n",
    "\n",
    "# for image_dir in os.listdir(train_top_level_dir):\n",
    "#     if not image_dir.startswith('.'):\n",
    "#         image_names = os.listdir(os.path.join(train_top_level_dir, image_dir))\n",
    "#         image_names = [image_name for image_name in image_names if not image_name.startswith('.')]\n",
    "#         image_count = len(image_names)\n",
    "        \n",
    "#         category_to_int_dict[image_dir] = image_count\n",
    "\n",
    "# top_level_set = set()\n",
    "\n",
    "# for key, value in category_to_int_dict.iteritems():\n",
    "#     top_level_category = key.split('->')[0].strip()\n",
    "#     top_level_set.add(top_level_category)\n",
    "\n",
    "# top_level_set\n",
    "\n",
    "# top_level_count_dict = dict()\n",
    "\n",
    "# for top_level in top_level_set:\n",
    "#     top_level_count_dict[top_level] = 0\n",
    "\n",
    "# top_level_count_dict\n",
    "\n",
    "# for image_dir in os.listdir(train_top_level_dir):\n",
    "#     if not image_dir.startswith('.'):\n",
    "#         top_level_category = image_dir.split('->')[0].strip()\n",
    "        \n",
    "#         image_names = os.listdir(os.path.join(train_top_level_dir, image_dir))\n",
    "#         image_names = [image_name for image_name in image_names if not image_name.startswith('.')]\n",
    "#         image_count = len(image_names)\n",
    "        \n",
    "#         top_level_count_dict[top_level_category] += image_count\n",
    "\n",
    "# print top_level_count_dict\n",
    "\n",
    "# print sum([val for val in top_level_count_dict.values()])\n",
    "\n",
    "# import operator\n",
    "\n",
    "# category_to_int_dict_sorted = sorted(category_to_int_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# print category_to_int_dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_labels = list(itertools.chain.from_iterable([tup[0]] * tup[1] for tup in category_to_int_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reverse labels as category_to_int_dict.values() returns values from the last category\n",
    "category_labels.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create top level index to image.jpeg dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_level_idx_to_image_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_level_idx_to_image_dict = dict()\n",
    "\n",
    "for image_dir in os.listdir(train_top_level_dir):\n",
    "    if not image_dir.startswith('.'):\n",
    "        image_dir_idx = category_to_int_dict[image_dir][0]\n",
    "        print image_dir, image_dir_idx\n",
    "        \n",
    "        top_level_idx_to_image_dict[image_dir_idx] = dict()\n",
    "        image_idx = 0\n",
    "\n",
    "        image_names = os.listdir(os.path.join(train_top_level_dir, image_dir))\n",
    "        \n",
    "        for image_name in image_names:\n",
    "            if not image_name.startswith('.'):\n",
    "                image_path = os.path.join(train_top_level_dir, image_dir, image_name)\n",
    "                top_level_idx_to_image_dict[image_dir_idx][image_idx] = image_path\n",
    "                image_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_level_idx_to_image_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dir = '../data/images_sample/train_top_level/'\n",
    "train_dir_above = '../data/images_sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_count = len(category_labels)\n",
    "img_width = 299\n",
    "img_height = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def largest_divisor(n, threshold=100):\n",
    "    factors_set = set(reduce(list.__add__, ([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0)))\n",
    "    factors_list = [i for i in factors_set if i <= threshold]\n",
    "    factors_list.sort()\n",
    "    return factors_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data Genenerator\n",
    "def load_data_generator():\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = load_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator = datagen.flow_from_directory(train_dir, \n",
    "                                        target_size=(img_width, img_height), \n",
    "                                        batch_size=largest_divisor(image_count), \n",
    "                                        class_mode=None, \n",
    "                                        shuffle=False, \n",
    "                                        seed=1368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = ResNet50(include_top=False, weights='imagenet', input_tensor=None)\n",
    "model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None)\n",
    "# model = VGG16(include_top=False, weights='imagenet', input_tensor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bottleneck_feats = model.predict_generator(generator, val_samples=generator.N, max_q_size=20, nb_worker=1)\n",
    "# np.save(open(train_dir_above + 'model/' + 'bottleneck_features.npy', 'w'), bottleneck_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottleneck_feats = np.load(open('../data/images_sample/search_features/search_features.npy'))\n",
    "# bottleneck_feats = np.load(open('../data/images/search_features/search_features.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottleneck_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "- How to featurize new search image and calculate cosine similiarity?\n",
    "- How to filter by category?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Process search image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cosine_similarity(bottleneck_features):\n",
    "#     csim = bottleneck_features.dot(bottleneck_features.T)\n",
    "#     if not isinstance(csim, np.ndarray):\n",
    "#         csim = csim.toarray()\n",
    "#     norms = np.array([np.sqrt(np.diagonal(csim))])\n",
    "#     return (csim / norms / norms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_image_dir_path = '../data/images_sample/search_image/'\n",
    "search_images = os.listdir(search_image_dir_path)\n",
    "search_images = [search_image for search_image in search_images if not search_image.startswith('.')]\n",
    "search_image_path = os.path.join(search_image_dir_path, search_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(search_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_image = image.load_img(search_image_path, target_size=(299, 299))\n",
    "search_image = image.img_to_array(search_image)\n",
    "search_image = np.multiply(search_image, 1. / 255)\n",
    "search_image = np.expand_dims(search_image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_image_features = model.predict(search_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cosine similarity loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_features = np.load(open('../data/images/search_features/search_features.npy'))\n",
    "search_image_features = search_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# csim = cosine_similarity(search_image_features, bottleneck_feats)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# csim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_cosine_similarity_sklearn(row, search_image_features):\n",
    "#     return cosine_similarity(row, search_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cosine_similarity_scipy(row, search_image_features):\n",
    "    return 1 - spatial.distance.cosine(row, search_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def time_sklearn_csim():\n",
    "#     return np.apply_along_axis(get_cosine_similarity_sklearn, axis=1, arr=bottleneck_feats, search_image_features=search_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_scipy_csim():\n",
    "    return np.apply_along_axis(get_cosine_similarity_scipy, axis=1, arr=search_features, search_image_features=search_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit -n 100 time_sklearn_csim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.73 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 time_scipy_csim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_scipy(search_image_features, search_features):\n",
    "    return np.apply_along_axis(get_cosine_similarity_scipy, axis=1, arr=search_features, search_image_features=search_image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csim = cosine_similarity_scipy(search_image_features, search_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Filter search features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_filter = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add category labels to bottleneck_feats\n",
    "bottleneck_feats = np.load(open('../data/images_sample/model/bottleneck_features.npy'))\n",
    "bottleneck_feats = np.insert(bottleneck_feats, 0, category_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if search_filter == -1:\n",
    "    bottleneck_feats = bottleneck_feats[:, 1:]\n",
    "else:\n",
    "    bottleneck_filter = bottleneck_feats[:, 0] == search_filter\n",
    "    bottleneck_feats = bottleneck_feats[bottleneck_filter, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print search_image_features.shape\n",
    "print bottleneck_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cosine similarity between search image features and bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cosine_similarity(bottleneck_features):\n",
    "#     csim = bottleneck_features.dot(bottleneck_features.T)\n",
    "#     if not isinstance(csim, np.ndarray):\n",
    "#         csim = csim.toarray()\n",
    "#     norms = np.array([np.sqrt(np.diagonal(csim))])\n",
    "#     return (csim / norms / norms.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Does not work\n",
    "# spatial.distance.cosine(search_image_features, bottleneck_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csim = cosine_similarity(search_image_features, bottleneck_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(csim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combined_features = np.vstack([search_image_features, bottleneck_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# csim = cosine_similarity(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.argsort(-csim[0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity_threshold = 0.58\n",
    "\n",
    "most_similar = np.argsort(-csim[0])[:10]\n",
    "\n",
    "# Exclude similar images below a certain similarity threshold\n",
    "most_similar = [idx for idx in most_similar if csim[0, idx] > similarity_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print most_similar\n",
    "\n",
    "if search_filter == -1:\n",
    "    image_lookup_dict = idx_to_image_dict\n",
    "else:\n",
    "    image_lookup_dict = top_level_idx_to_image_dict[search_filter]\n",
    "\n",
    "for i in most_similar:\n",
    "    image_path = image_lookup_dict[i]\n",
    "    print image_path\n",
    "    image_display = plt.imread(image_path)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image_display.astype('uint8'))\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels.h5'\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      border_mode='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50(include_top=True, weights='imagenet',\n",
    "             input_tensor=None):\n",
    "    '''Instantiate the ResNet50 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. xput of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        if include_top:\n",
    "            input_shape = (3, 224, 224)\n",
    "        else:\n",
    "            input_shape = (3, 224, 224)\n",
    "    else:\n",
    "        if include_top:\n",
    "            input_shape = (224, 224, 3)\n",
    "        else:\n",
    "            input_shape = (224, 224, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(1000, activation='softmax', name='fc1000')(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        print('K.image_dim_ordering:', K.image_dim_ordering())\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('resnet50_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='1c1f8f5b0c8ee28fe9d950625a230e1c')\n",
    "            else:\n",
    "                weights_path = get_file('resnet50_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='f64f049c92468c9affcd44b0976cdafe')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "        else:\n",
    "            if include_top:\n",
    "                weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        TF_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "            else:\n",
    "                weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels.h5'\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def conv2d_bn(x, nb_filter, nb_row, nb_col,\n",
    "              border_mode='same', subsample=(1, 1),\n",
    "              name=None):\n",
    "    '''\n",
    "    Utility function to apply conv + BN.\n",
    "    '''\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      activation='relu',\n",
    "                      border_mode=border_mode,\n",
    "                      name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionV3(include_top=True, weights='imagenet',\n",
    "                input_tensor=None):\n",
    "    '''Instantiate the Inception v3 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    Note that the default input image size for this model is 299x299.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        if include_top:\n",
    "            input_shape = (3, 299, 299)\n",
    "        else:\n",
    "            input_shape = (3, 299, 299)\n",
    "    else:\n",
    "        if include_top:\n",
    "            input_shape = (299, 299, 3)\n",
    "        else:\n",
    "            input_shape = (299, 299, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "    # with stride=2 border='valid', output becomes (299-1)/2 = 149 x 149\n",
    "    x = conv2d_bn(x, 32, 3, 3, border_mode='valid')  # 149 - 2 = 147 x 147\n",
    "    x = conv2d_bn(x, 64, 3, 3)  # 147 x 147\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)  # 49\n",
    "\n",
    "    x = conv2d_bn(x, 80, 1, 1, border_mode='valid')\n",
    "    x = conv2d_bn(x, 192, 3, 3, border_mode='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    for i in range(3):\n",
    "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "        x = merge([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(i))\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3,\n",
    "                             subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = merge([branch3x3, branch3x3dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed4')\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(5 + i))\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                          subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 3, 3,\n",
    "                            subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = merge([branch3x3, branch7x7x3, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed8')\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = merge([branch3x3_1, branch3x3_2],\n",
    "                          mode='concat', concat_axis=channel_axis,\n",
    "                          name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = merge([branch3x3dbl_1, branch3x3dbl_2],\n",
    "                             mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = merge([branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(9 + i))\n",
    "\n",
    "    x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)  # Moved here for transfer learning\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        # x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n",
    "        # x = Flatten(name='flatten')(x)\n",
    "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='b3baf3070cc4bf476d43a2ea61b0ca5f')\n",
    "            else:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='79aaa90ab4372b4593ba3df64e142f05')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "        else:\n",
    "            if include_top:\n",
    "                weights_path = get_file('inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        TF_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='fe114b3ff2ea4bf891e9353d1bbfb32f')\n",
    "            else:\n",
    "                weights_path = get_file('inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='2f3609166de1d967d1a481094754f691')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5'\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='imagenet',\n",
    "          input_tensor=None):\n",
    "    '''Instantiate the VGG16 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        if include_top:\n",
    "            input_shape = (3, 224, 224)\n",
    "        else:\n",
    "            input_shape = (3, 224, 224)\n",
    "    else:\n",
    "        if include_top:\n",
    "            input_shape = (224, 224, 3)\n",
    "        else:\n",
    "            input_shape = (224, 224, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # Block 1\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(img_input)\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x)\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)  # Add flattern\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        # x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        print('K.image_dim_ordering:', K.image_dim_ordering())\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n",
    "            else:\n",
    "                weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "        else:\n",
    "            if include_top:\n",
    "                weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        TF_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n",
    "            else:\n",
    "                weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Understanding InceptionV3 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, nb_filter, nb_row, nb_col,\n",
    "              border_mode='same', subsample=(1, 1),\n",
    "              name=None):\n",
    "    '''\n",
    "    Utility function to apply conv + BN.\n",
    "    '''\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      activation='relu',\n",
    "                      border_mode=border_mode,\n",
    "                      name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name)(x)\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=(3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, subsample=(2, 2), border_mode='valid', input_shape=(3, 299, 299)))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, 3, 3, border_mode='valid'))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(80, 1, 1, border_mode='valid'))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Convolution2D(192, 3, 3, border_mode='valid'))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = conv2d_bn(img_input, 32, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "# with stride=2 border='valid', output becomes (299-1)/2 = 149 x 149\n",
    "x = conv2d_bn(x, 32, 3, 3, border_mode='valid')  # 149 - 2 = 147 x 147\n",
    "x = conv2d_bn(x, 64, 3, 3)  # 147 x 147\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)  # 49\n",
    "\n",
    "x = conv2d_bn(x, 80, 1, 1, border_mode='valid')\n",
    "x = conv2d_bn(x, 192, 3, 3, border_mode='valid')\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2))(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
