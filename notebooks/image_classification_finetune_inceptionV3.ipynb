{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Input, BatchNormalization, merge, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from logger import logger\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels.h5'\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "def conv2d_bn(x, nb_filter, nb_row, nb_col,\n",
    "              border_mode='same', subsample=(1, 1),\n",
    "              name=None):\n",
    "    '''Utility function to apply conv + BN.\n",
    "    '''\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      activation='relu',\n",
    "                      border_mode=border_mode,\n",
    "                      name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionV3(include_top=True, weights='imagenet',\n",
    "                input_tensor=None):\n",
    "    '''Instantiate the Inception v3 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    Note that the default input image size for this model is 299x299.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        if include_top:\n",
    "            input_shape = (3, 299, 299)\n",
    "        else:\n",
    "            input_shape = (3, 299, 299)\n",
    "    else:\n",
    "        if include_top:\n",
    "            input_shape = (299, 299, 3)\n",
    "        else:\n",
    "            input_shape = (None, None, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, border_mode='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 80, 1, 1, border_mode='valid')\n",
    "    x = conv2d_bn(x, 192, 3, 3, border_mode='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    for i in range(3):\n",
    "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "        x = merge([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(i))\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3,\n",
    "                             subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = merge([branch3x3, branch3x3dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed4')\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(5 + i))\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                          subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 3, 3,\n",
    "                            subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = merge([branch3x3, branch7x7x3, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed8')\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = merge([branch3x3_1, branch3x3_2],\n",
    "                          mode='concat', concat_axis=channel_axis,\n",
    "                          name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = merge([branch3x3dbl_1, branch3x3dbl_2],\n",
    "                             mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = merge([branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(9 + i))\n",
    "\n",
    "    x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)  # Moved here for transfer learning\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        # x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='b3baf3070cc4bf476d43a2ea61b0ca5f')\n",
    "            else:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='79aaa90ab4372b4593ba3df64e142f05')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "        else:\n",
    "            if include_top:\n",
    "                weights_path = get_file('inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        TF_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='fe114b3ff2ea4bf891e9353d1bbfb32f')\n",
    "            else:\n",
    "                weights_path = get_file('inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='2f3609166de1d967d1a481094754f691')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create category dictionary\n",
    "def create_category_dict(train_dir):\n",
    "    categories = os.listdir(train_dir)\n",
    "\n",
    "    # Initialize category dict\n",
    "    category_dict = dict()\n",
    "    idx = 0\n",
    "    for category in categories:\n",
    "        if not category.startswith('.'):\n",
    "            category_dict[idx] = category\n",
    "            idx += 1\n",
    "\n",
    "    return category_dict\n",
    "\n",
    "# Create labels for training and testing.\n",
    "def create_labels(load_dir, category_dict):\n",
    "    train_tuples = list()\n",
    "\n",
    "    # Create tuples of category index and counts\n",
    "    for image_dir in os.listdir(load_dir):\n",
    "        if not image_dir.startswith('.'):\n",
    "            image_count = len(os.listdir(os.path.join(load_dir, image_dir)))\n",
    "            train_tuples.append((category_dict.keys()[category_dict.values().index(image_dir)], image_count))\n",
    "\n",
    "    # Create training labels\n",
    "    train_labels = to_categorical(list(itertools.chain.from_iterable([[tup[0]] * tup[1] for tup in train_tuples])))\n",
    "\n",
    "    logger.info('{} labels created ({} categories, {} labels)'\n",
    "                .format(load_dir, len(train_tuples), sum([tup[1] for tup in train_tuples])))\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dir = '../data/images_clothes/train/'\n",
    "category_dict = create_category_dict(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(open('../data/images_clothes/bottleneck_features/inception_3/bottleneck_feat_train.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2048)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-11-20 14:34:41,556 - ../data/images_clothes/train/ labels created (65 categories, 176759 labels)\n",
      "INFO:__log__:../data/images_clothes/train/ labels created (65 categories, 176759 labels)\n"
     ]
    }
   ],
   "source": [
    "train_labels = create_labels(train_dir, category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load inception without top layer\n",
    "model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3, 299, 299)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pool{ds=(8, 8), ignore_border=True, st=(8, 8), padding=(0, 0), mode='average_exc_pad'}.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create top model\n",
    "x = model.output\n",
    "x = Flatten(name='flatten')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Create top model\n",
    "x = model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(512, activation='relu', init='glorot_uniform')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu', init='glorot_uniform')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "pred_layer = Dense(output_dim=train_labels.shape[1], activation='softmax')(x)\n",
    "top_model = Model(input=model.input, output=pred_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create top model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Dense(512, activation='relu', init='glorot_uniform'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(512, activation='relu', init='glorot_uniform'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(output_dim=train_labels.shape[1], activation='softmax'))\n",
    "\n",
    "# Load weights\n",
    "top_model.load_weights('../data/images_clothes/model/final_layer_weights_inception3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x188945410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1889d7450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1974f9990>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1907d3190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1907d3e90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19070ef50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19070e4d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x182759bd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x182759ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x182766dd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x187a52e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18887a990>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1888dae10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18ce2ae90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18ce34b90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18aaa0d90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18da96b90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18aab8150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18dab2290>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x18ff70f50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1888e5050>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18c7f1390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18dbfc0d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18ff54890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1888da5d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18c7f1e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18dbfc990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18ff8bc50>,\n",
       " <keras.engine.topology.Merge at 0x192d8fd10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192f155d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192f3bd50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192dfce90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192fa2ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192e06a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192fb36d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x1938d4b90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192d82f50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192e75b90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193827790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1938e0fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192d9f710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192e41590>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192ffa2d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1938ff150>,\n",
       " <keras.engine.topology.Merge at 0x193969250>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193c35750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193c0e510>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1939b1fd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193c7a4d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193b12c10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193cb97d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x193de3390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193969390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193b7cd90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193d19690>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193de3850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193942850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193b8a790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193d2a290>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193df7f90>,\n",
       " <keras.engine.topology.Merge at 0x193e5c5d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193ed91d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193e8ce50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193f39e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193f53050>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1888dafd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193fc0110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193e6d3d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193fc0cd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x19407a250>,\n",
       " <keras.engine.topology.Merge at 0x19407a410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1943d9550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1943c21d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19457c890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1945bf690>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1940d1e90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19461c8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1941067d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1946293d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1941bd990>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194839350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194304290>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194807f10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x194a392d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19407a550>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19436d3d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1948f0d90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194a39710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194065b90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19437d0d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1949266d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194a49a50>,\n",
       " <keras.engine.topology.Merge at 0x194a59f90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194fc5050>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194fc5a10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195025e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194fee9d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194bbc650>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1951df690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194bcc150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195208c50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194cae090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195322050>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194ba1cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195322c10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x195579c90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194a91dd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194e69ed0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19543dc90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195588910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194ac1490>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194f59250>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19541a410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195596a50>,\n",
       " <keras.engine.topology.Merge at 0x195723fd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195b1af50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195c378d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195ca4210>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195ca4ad0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195807950>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195e6ced0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19583a7d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195e7aad0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195918a90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195f93310>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195929490>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195f87750>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x1961fabd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195732150>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195adf8d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1960b02d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196205250>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195717290>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1958f4ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1960ca450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1961d3bd0>,\n",
       " <keras.engine.topology.Merge at 0x196240f10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1968bcb10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1968c9c50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196ab9110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1968ab750>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1964c2090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196bf9590>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1964c2950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196bd3bd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1965bac50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196d2cd90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1965c6950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196d7d850>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x197049850>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194a91150>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19659ae90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196ed3710>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197049150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196290810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196761790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196ee4410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197068590>,\n",
       " <keras.engine.topology.Merge at 0x197152a90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1972c62d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197371090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1973d9690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1973e9090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197152bd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197443510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19715f7d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1973fdfd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19725b7d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197469e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197239050>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197e60910>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x197eb9bd0>,\n",
       " <keras.engine.topology.Merge at 0x197eb9e10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198f79a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x198f8c590>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198250e90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198ff1890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x198261a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x199000590>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1982ca090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198d39790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a217c90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a441e10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x19a4b4790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197eb9f90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1982be650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x198d71190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a221a50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a45b190>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a4b4d10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197ecba90>,\n",
       " <keras.engine.topology.Merge at 0x198f79950>,\n",
       " <keras.engine.topology.Merge at 0x19a4b4650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a4c7d10>,\n",
       " <keras.engine.topology.Merge at 0x19a80c690>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19b3b2950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19b3dced0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19aaf3f50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19b7d51d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19ab104d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19b3a78d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19ab77790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19abe7b50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19be21410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19c156450>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x19c365a10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a80c190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19ab8a390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19b361850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19be31110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19c12f910>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19c370e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a825590>,\n",
       " <keras.engine.topology.Merge at 0x19b3a7190>,\n",
       " <keras.engine.topology.Merge at 0x19c365c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19c383f90>,\n",
       " <keras.engine.topology.Merge at 0x19c3f6310>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x197eb9f50>]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "img_input = Input(shape=(3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorVariable' object has no attribute 'inbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-0adc7aff3c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# first layer in model: check that it is an input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0;31m# create an input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_input_shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorVariable' object has no attribute 'inbound_nodes'"
     ]
    }
   ],
   "source": [
    "full_model.add(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "A layer added to a Sequential model must not already be connected somewhere else. Model received layer input_24 which has 2 pre-existing inbound connections.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-83227c87f97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfull_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    281\u001b[0m                                 \u001b[0;34m'Model received layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                                 \u001b[0;34m' which has '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                                 ' pre-existing inbound connections.')\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: A layer added to a Sequential model must not already be connected somewhere else. Model received layer input_24 which has 2 pre-existing inbound connections."
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    full_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Flatten at 0x19c4446d0>,\n",
       " <keras.layers.core.Dense at 0x192057610>,\n",
       " <keras.layers.core.Dropout at 0x1901c2fd0>,\n",
       " <keras.layers.core.Dense at 0x18c1fbb10>,\n",
       " <keras.layers.core.Dropout at 0x192057ed0>,\n",
       " <keras.layers.core.Dense at 0x18c361790>]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x188945410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1889d7450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1974f9990>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1907d3190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1907d3e90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19070ef50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19070e4d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x182759bd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x182759ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x182766dd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x187a52e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18887a990>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1888dae10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18ce2ae90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18ce34b90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18aaa0d90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18da96b90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18aab8150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18dab2290>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x18ff70f50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1888e5050>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18c7f1390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18dbfc0d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x18ff54890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1888da5d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18c7f1e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18dbfc990>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18ff8bc50>,\n",
       " <keras.engine.topology.Merge at 0x192d8fd10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192f155d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192f3bd50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192dfce90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192fa2ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192e06a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192fb36d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x1938d4b90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192d82f50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x192e75b90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193827790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1938e0fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192d9f710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192e41590>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x192ffa2d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1938ff150>,\n",
       " <keras.engine.topology.Merge at 0x193969250>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193c35750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193c0e510>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1939b1fd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193c7a4d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193b12c10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193cb97d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x193de3390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193969390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193b7cd90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193d19690>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193de3850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193942850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193b8a790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193d2a290>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193df7f90>,\n",
       " <keras.engine.topology.Merge at 0x193e5c5d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193ed91d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193e8ce50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193f39e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193f53050>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1888dafd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x193fc0110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193e6d3d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x193fc0cd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x19407a250>,\n",
       " <keras.engine.topology.Merge at 0x19407a410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1943d9550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1943c21d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19457c890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1945bf690>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1940d1e90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19461c8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1941067d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1946293d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1941bd990>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194839350>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194304290>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194807f10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x194a392d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19407a550>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19436d3d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1948f0d90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194a39710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194065b90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19437d0d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1949266d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194a49a50>,\n",
       " <keras.engine.topology.Merge at 0x194a59f90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194fc5050>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194fc5a10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195025e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194fee9d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194bbc650>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1951df690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194bcc150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195208c50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194cae090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195322050>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194ba1cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195322c10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x195579c90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194a91dd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194e69ed0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19543dc90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195588910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194ac1490>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x194f59250>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19541a410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195596a50>,\n",
       " <keras.engine.topology.Merge at 0x195723fd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195b1af50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195c378d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195ca4210>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195ca4ad0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195807950>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195e6ced0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19583a7d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195e7aad0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195918a90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195f93310>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195929490>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195f87750>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x1961fabd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195732150>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x195adf8d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1960b02d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196205250>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x195717290>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1958f4ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1960ca450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1961d3bd0>,\n",
       " <keras.engine.topology.Merge at 0x196240f10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1968bcb10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1968c9c50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196ab9110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1968ab750>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1964c2090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196bf9590>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1964c2950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196bd3bd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1965bac50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196d2cd90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1965c6950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196d7d850>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x197049850>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x194a91150>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19659ae90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x196ed3710>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197049150>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196290810>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196761790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x196ee4410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197068590>,\n",
       " <keras.engine.topology.Merge at 0x197152a90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1972c62d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197371090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1973d9690>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1973e9090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197152bd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197443510>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19715f7d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1973fdfd0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19725b7d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197469e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197239050>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197e60910>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x197eb9bd0>,\n",
       " <keras.engine.topology.Merge at 0x197eb9e10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198f79a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x198f8c590>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198250e90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198ff1890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x198261a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x199000590>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x1982ca090>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x198d39790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a217c90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a441e10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x19a4b4790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x197eb9f90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1982be650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x198d71190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a221a50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a45b190>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a4b4d10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x197ecba90>,\n",
       " <keras.engine.topology.Merge at 0x198f79950>,\n",
       " <keras.engine.topology.Merge at 0x19a4b4650>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a4c7d10>,\n",
       " <keras.engine.topology.Merge at 0x19a80c690>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19b3b2950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19b3dced0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19aaf3f50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19b7d51d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19ab104d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19b3a78d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19ab77790>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19abe7b50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19be21410>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19c156450>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x19c365a10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19a80c190>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19ab8a390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19b361850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19be31110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19c12f910>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x19c370e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19a825590>,\n",
       " <keras.engine.topology.Merge at 0x19b3a7190>,\n",
       " <keras.engine.topology.Merge at 0x19c365c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x19c383f90>,\n",
       " <keras.engine.topology.Merge at 0x19c3f6310>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x197eb9f50>]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x, dim_ordering='default'):\n",
    "    if dim_ordering == 'default':\n",
    "        dim_ordering = K.image_dim_ordering()\n",
    "    assert dim_ordering in {'tf', 'th'}\n",
    "\n",
    "    if dim_ordering == 'th':\n",
    "        x[:, 0, :, :] -= 103.939\n",
    "        x[:, 1, :, :] -= 116.779\n",
    "        x[:, 2, :, :] -= 123.68\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, ::-1, :, :]\n",
    "    else:\n",
    "        x[:, :, :, 0] -= 103.939\n",
    "        x[:, :, :, 1] -= 116.779\n",
    "        x[:, :, :, 2] -= 123.68\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, :, :, ::-1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASS_INDEX = None\n",
    "CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "\n",
    "def decode_predictions(preds, top=5):\n",
    "    global CLASS_INDEX\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
    "        raise ValueError('`decode_predictions` expects '\n",
    "                         'a batch of predictions '\n",
    "                         '(i.e. a 2D array of shape (samples, 1000)). '\n",
    "                         'Found array with shape: ' + str(preds.shape))\n",
    "    if CLASS_INDEX is None:\n",
    "        fpath = get_file('imagenet_class_index.json',\n",
    "                         CLASS_INDEX_PATH,\n",
    "                         cache_subdir='models')\n",
    "        CLASS_INDEX = json.load(open(fpath))\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = InceptionV3(include_top=True, weights='imagenet')\n",
    "\n",
    "img_path = '../data/images_clothes/pred_image/B000KPX728.jpg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted:', [[(u'n04041544', u'radio', 1.0), (u'n04285008', u'sports_car', 8.676351e-33), (u'n03208938', u'disk_brake', 9.5391894e-39), (u'n03450230', u'gown', 1.0475182e-39), (u'n03126707', u'crane', 1.0458311e-40)]])\n",
      "Time taken: 98.307772 secs\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))\n",
    "end_time = datetime.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Time taken: {} secs'.format(elapsed_time.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with VGG to test speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5'\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='imagenet',\n",
    "          input_tensor=None):\n",
    "    '''Instantiate the VGG16 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        if include_top:\n",
    "            input_shape = (3, 224, 224)\n",
    "        else:\n",
    "            input_shape = (3, None, None)\n",
    "    else:\n",
    "        if include_top:\n",
    "            input_shape = (224, 224, 3)\n",
    "        else:\n",
    "            input_shape = (None, None, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # Block 1\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(img_input)\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x)\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        print('K.image_dim_ordering:', K.image_dim_ordering())\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n",
    "            else:\n",
    "                weights_path = get_file('vgg16_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "        else:\n",
    "            if include_top:\n",
    "                weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        TF_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models')\n",
    "            else:\n",
    "                weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('K.image_dim_ordering:', 'th')\n",
      "('Input image shape:', (1, 3, 224, 224))\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "img_path = '../data/images_clothes/pred_image/B000KPX728.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted:', [[(u'n03595614', u'jersey', 0.97483015), (u'n04370456', u'sweatshirt', 0.010700147), (u'n03498962', u'hatchet', 0.0012513819), (u'n03787032', u'mortarboard', 0.00080714229), (u'n03929660', u'pick', 0.00057887461)]])\n",
      "Time taken: 88.241128 secs\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))\n",
    "end_time = datetime.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Time taken: {} secs'.format(elapsed_time.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
