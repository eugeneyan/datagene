{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Input, BatchNormalization, merge, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from logger import logger\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels.h5'\n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, nb_filter, nb_row, nb_col,\n",
    "              border_mode='same', subsample=(1, 1),\n",
    "              name=None):\n",
    "    '''Utility function to apply conv + BN.\n",
    "    '''\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      activation='relu',\n",
    "                      border_mode=border_mode,\n",
    "                      name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionV3(include_top=True, weights='imagenet',\n",
    "                input_tensor=None):\n",
    "    '''Instantiate the Inception v3 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    Note that the default input image size for this model is 299x299.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        if include_top:\n",
    "            input_shape = (3, 299, 299)\n",
    "        else:\n",
    "            input_shape = (3, 299, 299)\n",
    "    else:\n",
    "        if include_top:\n",
    "            input_shape = (299, 299, 3)\n",
    "        else:\n",
    "            input_shape = (299, 299, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, border_mode='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 80, 1, 1, border_mode='valid')\n",
    "    x = conv2d_bn(x, 192, 3, 3, border_mode='valid')\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    for i in range(3):\n",
    "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "        x = merge([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(i))\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3,\n",
    "                             subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = merge([branch3x3, branch3x3dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed4')\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(5 + i))\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = merge([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                          subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 3, 3,\n",
    "                            subsample=(2, 2), border_mode='valid')\n",
    "\n",
    "    branch_pool = AveragePooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = merge([branch3x3, branch7x7x3, branch_pool],\n",
    "              mode='concat', concat_axis=channel_axis,\n",
    "              name='mixed8')\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = merge([branch3x3_1, branch3x3_2],\n",
    "                          mode='concat', concat_axis=channel_axis,\n",
    "                          name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = merge([branch3x3dbl_1, branch3x3dbl_2],\n",
    "                             mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), border_mode='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = merge([branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "                  mode='concat', concat_axis=channel_axis,\n",
    "                  name='mixed' + str(9 + i))\n",
    "\n",
    "    x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)  # Moved here for transfer learning\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        # x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            if include_top:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels.h5',\n",
    "                                        TH_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='b3baf3070cc4bf476d43a2ea61b0ca5f')\n",
    "            else:\n",
    "                weights_path = get_file('inception_v3_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='79aaa90ab4372b4593ba3df64e142f05')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "        else:\n",
    "            if include_top:\n",
    "                weights_path = get_file('inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                        TF_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='fe114b3ff2ea4bf891e9353d1bbfb32f')\n",
    "            else:\n",
    "                weights_path = get_file('inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='2f3609166de1d967d1a481094754f691')\n",
    "            model.load_weights(weights_path)\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eugeneyan/.virtualenvs/datagene/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/Users/eugeneyan/.virtualenvs/datagene/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/Users/eugeneyan/.virtualenvs/datagene/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n",
      "/Users/eugeneyan/.virtualenvs/datagene/lib/python2.7/site-packages/keras/backend/theano_backend.py:1505: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='average_exc_pad')\n",
      "/Users/eugeneyan/.virtualenvs/datagene/lib/python2.7/site-packages/keras/backend/theano_backend.py:1505: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='average_exc_pad')\n",
      "/Users/eugeneyan/.virtualenvs/datagene/lib/python2.7/site-packages/keras/backend/theano_backend.py:1505: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='average_exc_pad')\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add top model\n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(512, activation='relu', init='glorot_uniform')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu', init='glorot_uniform')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "pred_layer = Dense(output_dim=8, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=pred_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 299\n",
    "img_height = 299\n",
    "train_dir = '../data/images_clothes/train_subset'\n",
    "val_dir = '../data/images_clothes/val_subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 images belonging to 8 classes.\n",
      "Found 760 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load Data Genenerator\n",
    "def load_data_generator():\n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    return datagen\n",
    "\n",
    "# train_datagen = load_data_generator()\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=(img_width, img_height),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True,\n",
    "                                              seed=1368)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(val_dir,\n",
    "                                              target_size=(img_width, img_height),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True,\n",
    "                                              seed=1368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(train_generator, samples_per_epoch=1000, nb_epoch=10, validation_data=validation_generator,\n",
    "                    nb_val_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
